{
  "name": "Dataflow",
  "entries": {
    "2025-08-26": [
      {
        "kind": "Fixed",
        "content": "Dataflow [Runner v2](https://cloud.google.com/dataflow/docs/runner-v2) fixes an issue that could cause data discrepancies when using splittable DoFns, particularly when processing large datasets as side inputs. This fix ensures that all data is accurately processed and transmitted within the pipeline. This improvement is available in recent Dataflow service releases, and is automatically enabled when using Dataflow Runner v2.\n\n**Note:** After this fix, pipelines that previously experienced data loss due to this issue might consume more resources (such as CPU, memory, and processing time) because more data is being processed. This increase in resource usage is expected and reflects the correct behavior of the pipeline.",
        "summary": {
          "title": "Dataflow Runner v2 Fixes Data Discrepancies",
          "summary": "Runner v2 resolves data discrepancies with splittable DoFns and large side inputs. Data is now processed and transmitted accurately."
        }
      }
    ],
    "2025-08-11": [
      {
        "kind": "Feature",
        "content": "Dataflow now automatically detects performance bottlenecks in streaming jobs. You can see the cause of the bottleneck in the **Step Info** panel to help with troubleshooting.\n\nFor more information, see [Troubleshoot bottlenecks](https://cloud.google.com/dataflow/docs/guides/troubleshoot-bottlenecks).",
        "summary": {
          "title": "Dataflow Bottleneck Detection",
          "summary": "Dataflow now automatically detects performance bottlenecks in streaming jobs."
        }
      }
    ],
    "2025-06-26": [
      {
        "kind": "Feature",
        "content": "Dataflow now supports an automated parallel update workflow for streaming jobs. This feature helps minimize disruption by launching a new replacement job that runs in parallel with the existing job. After a duration of time you specify, the old job is automatically drained.\n\nFor more information, see [Run parallel pipelines](https://cloud.google.com/dataflow/docs/guides/upgrade-guide#run-parallel-pipelines).",
        "summary": {
          "title": "Automated parallel update workflow for streaming jobs",
          "summary": "Dataflow now supports an automated parallel update workflow for streaming jobs. This feature helps minimize disruption by launching a new replacement job that runs in parallel with the existing job. After a duration of time you specify, the old job is automatically drained."
        }
      }
    ],
    "2025-06-09": [
      {
        "kind": "Feature",
        "content": "Dataflow now supports right fitting for streaming jobs. *Right fitting* lets you specify resource requirements for an entire pipeline or for specific pipeline steps. Previously, right fitting was only supported for batch pipelines. For more information, see [Streaming right fitting](https://cloud.google.com/dataflow/docs/guides/right-fitting#streaming-right-fitting).",
        "summary": {
          "title": "Dataflow now supports right fitting for streaming jobs",
          "summary": "Dataflow now supports right fitting for streaming jobs, allowing you to specify resource requirements for your entire pipeline or specific steps. This feature was previously only available for batch pipelines."
        }
      }
    ]
  }
}