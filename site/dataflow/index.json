{
  "name": "Dataflow",
  "entries": {
    "2026-02-02": [
      {
        "kind": "Feature",
        "content": "Dataflow Managed I/O now supports rolling upgrades for streaming jobs. With this\nfeature, Dataflow upgrades your Managed I/O connectors in running pipelines as\nnew connector versions become available. For more information, see\n[Automatic upgrades](https://docs.cloud.google.com/dataflow/docs/guides/managed-io#upgrades).",
        "summary": {
          "title": "Dataflow Managed I/O Rolling Upgrades",
          "summary": "Dataflow Managed I/O now supports rolling upgrades for streaming jobs. This feature allows Dataflow to upgrade your Managed I/O connectors in running pipelines automatically as new versions are released. This ensures your pipelines benefit from the latest connector improvements without manual intervention."
        }
      }
    ],
    "2026-01-20": [
      {
        "kind": "Feature",
        "content": "Dataflow is available in the Bangkok (`asia-southeast3`) region. Learn more\nabout [Google Cloud locations](https://cloud.google.com/about/locations).",
        "summary": {
          "title": "Dataflow now in Bangkok",
          "summary": "Dataflow is now available in the Bangkok region (asia-southeast3). You can now run your data processing jobs closer to your users in Southeast Asia. Learn more about Google Cloud locations."
        }
      }
    ],
    "2026-01-13": [
      {
        "kind": "Feature",
        "content": "Dataflow now serves a notice for when the Dataflow\n[Runner v2](https://docs.cloud.google.com/dataflow/docs/runner-v2) container image of a streaming pipeline\nwill be upgraded. To use a new image and avoid the scheduled maintenance, launch\na replacement job before the upgrade. For more information, see\n[Runner v2 harness update](https://docs.cloud.google.com/dataflow/docs/guides/common-errors#runner_v2_harness_update).",
        "summary": {
          "title": "Upcoming Dataflow Runner v2 Container Upgrades",
          "summary": "Dataflow now notifies users about upcoming upgrades to the Dataflow Runner v2 container image for streaming pipelines. To ensure uninterrupted service, launch a replacement job before the scheduled maintenance to utilize the new image."
        }
      }
    ],
    "2025-11-21": [
      {
        "kind": "Feature",
        "content": "Dataflow now supports speculative execution for batch pipelines. This feature mitigates the impact of slow-running tasks (*stragglers*) by launching a redundant execution of these tasks. The first task to finish is used, and the other is canceled, which can improve the overall completion time of your pipeline. This feature is generally available. For more information, see [Use speculative execution to avoid stragglers](https://docs.cloud.google.com/dataflow/docs/guides/large-pipeline-best-practices#backup-tasks).",
        "summary": {
          "title": "Speculative Execution for Dataflow Batch Pipelines",
          "summary": "Dataflow now supports speculative execution for batch pipelines to mitigate the impact of slow-running tasks. This feature can improve pipeline completion time by launching redundant tasks and using the first one to finish."
        }
      }
    ],
    "2025-09-24": [
      {
        "kind": "Feature",
        "content": "For jobs that use GPUs, Dataflow now supports the flex-start provisioning model. This flex-start provisioning model can improve your ability to get access to constrained GPU resources for short-duration workloads. This feature is available in Preview and is for batch pipelines only. For more information, see [Configure a provisioning model](https://cloud.google.com/dataflow/docs/gpu/use-gpus#optional_configure_a_provisioning_model).",
        "summary": {
          "title": "Dataflow GPU Access",
          "summary": "Dataflow now supports flex-start provisioning for GPU jobs, improving access to scarce GPU resources for short-term workloads. This feature is in Preview and intended for batch pipelines."
        }
      }
    ],
    "2025-09-08": [
      {
        "kind": "Feature",
        "content": "Dataflow now supports using [secure tags](https://cloud.google.com/firewall/docs/tags-firewalls-overview) to set firewall rules on worker VMs. For more information, see [Use secure tags with Dataflow](https://cloud.google.com/dataflow/docs/guides/routes-firewall#secure_tags).",
        "summary": {
          "title": "Secure Tags for Dataflow Workers",
          "summary": "Dataflow now supports secure tags for firewall rules on worker VMs."
        }
      }
    ],
    "2025-08-27": [
      {
        "kind": "Feature",
        "content": "Dataflow supports TPUs, Google's custom-designed AI accelerators that are optimized for large-scale AI/ML workloads. This feature lets you accelerate inference workloads on frameworks like PyTorch, JAX, and TensorFlow. This feature is [generally available](https://cloud.google.com/products#product-launch-stages) with an allowlist. For more information, see [Dataflow support for TPUs](https://cloud.google.com/dataflow/docs/tpu/tpu-support).",
        "summary": {
          "title": "Dataflow TPU Support",
          "summary": "Accelerate your AI/ML inference workloads with TPUs on Dataflow. Generally available with an allowlist."
        }
      },
      {
        "kind": "Feature",
        "content": "Dataflow supports [*specifically targeted* reservations](https://cloud.google.com/compute/docs/instances/reservations-overview#consumption-type) for pipelines using accelerators (GPUs or TPUs). This functionality is generally available with an allowlist. For more information, see [Use Compute Engine reservations with Dataflow](https://cloud.google.com/dataflow/docs/guides/compute-engine-reservations.md#reservations-accelerators).",
        "summary": {
          "title": "Dataflow now supports reservations for pipelines with accelerators.",
          "summary": "Dataflow now generally available supports [*specifically targeted* reservations](https://cloud.google.com/compute/docs/instances/reservations-overview#consumption_type) for pipelines using accelerators (GPUs or TPUs). For more information, see [Use Compute Engine reservations with Dataflow](https://cloud.google.com/dataflow/docs/guides/compute-engine-reservations.md#reservations-accelerators)."
        }
      },
      {
        "kind": "Changed",
        "content": "Dataflow supports NVIDIA® H100 and NVIDIA® H100 Mega GPU types. For more information, see [Dataflow support for GPUs](https://cloud.google.com/dataflow/docs/gpu/gpu-support).",
        "summary": {
          "title": "NVIDIA GPU Support in Dataflow",
          "summary": "Dataflow now supports NVIDIA H100 and H100 Mega GPUs, enhancing processing capabilities. For detailed information, refer to the official documentation on GPU support."
        }
      }
    ],
    "2025-08-26": [
      {
        "kind": "Fixed",
        "content": "Dataflow [Runner v2](https://cloud.google.com/dataflow/docs/runner-v2) fixes an issue that could cause data discrepancies when using splittable DoFns, particularly when processing large datasets as side inputs. This fix ensures that all data is accurately processed and transmitted within the pipeline. This improvement is available in recent Dataflow service releases, and is automatically enabled when using Dataflow Runner v2.\n\n**Note:** After this fix, pipelines that previously experienced data loss due to this issue might consume more resources (such as CPU, memory, and processing time) because more data is being processed. This increase in resource usage is expected and reflects the correct behavior of the pipeline.",
        "summary": {
          "title": "Dataflow Runner v2 Fixes Data Discrepancies",
          "summary": "Runner v2 resolves data discrepancies with splittable DoFns and large side inputs. Data is now processed and transmitted accurately."
        }
      }
    ],
    "2025-08-11": [
      {
        "kind": "Feature",
        "content": "Dataflow now automatically detects performance bottlenecks in streaming jobs. You can see the cause of the bottleneck in the **Step Info** panel to help with troubleshooting.\n\nFor more information, see [Troubleshoot bottlenecks](https://cloud.google.com/dataflow/docs/guides/troubleshoot-bottlenecks).",
        "summary": {
          "title": "Dataflow Bottleneck Detection",
          "summary": "Dataflow now automatically detects performance bottlenecks in streaming jobs."
        }
      }
    ],
    "2025-06-26": [
      {
        "kind": "Feature",
        "content": "Dataflow now supports an automated parallel update workflow for streaming jobs. This feature helps minimize disruption by launching a new replacement job that runs in parallel with the existing job. After a duration of time you specify, the old job is automatically drained.\n\nFor more information, see [Run parallel pipelines](https://cloud.google.com/dataflow/docs/guides/upgrade-guide#run-parallel-pipelines).",
        "summary": {
          "title": "Automated parallel update workflow for streaming jobs",
          "summary": "Dataflow now supports an automated parallel update workflow for streaming jobs. This feature helps minimize disruption by launching a new replacement job that runs in parallel with the existing job. After a duration of time you specify, the old job is automatically drained."
        }
      }
    ],
    "2025-06-09": [
      {
        "kind": "Feature",
        "content": "Dataflow now supports right fitting for streaming jobs. *Right fitting* lets you specify resource requirements for an entire pipeline or for specific pipeline steps. Previously, right fitting was only supported for batch pipelines. For more information, see [Streaming right fitting](https://cloud.google.com/dataflow/docs/guides/right-fitting#streaming-right-fitting).",
        "summary": {
          "title": "Dataflow now supports right fitting for streaming jobs",
          "summary": "Dataflow now supports right fitting for streaming jobs, allowing you to specify resource requirements for your entire pipeline or specific steps. This feature was previously only available for batch pipelines."
        }
      }
    ]
  }
}